{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defensive programming\n",
    "\n",
    "**Note**: This lesson draws heavily from, and in some parts quotes directly,\n",
    "the [Python Testing](http://katyhuff.github.io/python-testing/) lesson\n",
    "developed by Kathryn Huff. \n",
    "\n",
    "Untested code is broken code. Doing science with untested code is akin to using\n",
    "an experimental device that is uncalibrated, which is generally a bad idea.\n",
    "The best way to write code that works and keeps on working is to assume it's\n",
    "broken, and to build yourself some alarms for when its behavior is outside of\n",
    "what is expected. \n",
    "\n",
    "This mindset is often called **defensive programming**.\n",
    "\n",
    "In this lesson, we will learn about various flavors of testing code, including:\n",
    "\n",
    "1. [Assertions](http://katyhuff.github.io/python-testing/02-assertions.html)\n",
    "2. [Exceptions](http://katyhuff.github.io/python-testing/03-exceptions.html)\n",
    "3. [Unit Tests](http://katyhuff.github.io/python-testing/04-units.html)\n",
    "\n",
    "and we will write some of our own, too.\n",
    "\n",
    "#### Additional resources\n",
    "\n",
    "* [Python Testing](http://katyhuff.github.io/python-testing/) by Kathryn Huff\n",
    "* _[Effective Computation in Physics, Chapter 18](http://physics.codes/)_, A. Scopatz and K. Huff. O'Reilly Media. (2015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using assertions\n",
    "\n",
    "Learning objectives:\n",
    "* Assertions are one line tests embedded in code.\n",
    "* Assertions can halt execution if something unexpected happens.\n",
    "* Assertions are the building blocks of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``assert`` Python keyword tests the truth value of what follows, and if what follows evaluates to ``False``, then it raises an ``AssertionError`` (a type of ``Exception``, which we'll get to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert True == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "True is not False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b6907c482156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"True is not False\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: True is not False"
     ]
    }
   ],
   "source": [
    "assert True == False, \"True is not False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can follow up an assertion statement with a string giving what should be printed when the assertion rings false. We'll see how this is useful below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assertions as input enforcement\n",
    "\n",
    "A common use of assertions is to check that the inputs of a function \n",
    "meet the expectations of that function; that is, that they are valid\n",
    "given the assumptions that function needs to make about them. If we\n",
    "write a simple function that gets the mean of a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    return sum(num_list)/len(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([4, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding it an empty list gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e9e2222d800d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ee8a4f490b2f>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "mean([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some assertions. We'll also add in a docstring to make clear\n",
    "what we want this function to take, and what we want it to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    \"\"\"Return the mean of a list of numbers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_list : list\n",
    "        List of values to get arithmetic mean for.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Arithmetic mean.\n",
    "    \"\"\"\n",
    "    assert len(num_list) > 0, \"Cannot take an empty list\"\n",
    "    assert all([isinstance(i, (float, int)) for i in num_list]), \"List must only have numbers\"\n",
    "    \n",
    "    return sum(num_list)/len(num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two assertions that check:\n",
    "1. the list given is not empty.\n",
    "2. all elements in the list are either floating point numbers or integers.\n",
    "\n",
    "So now when we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot take an empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e9e2222d800d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-eb8f4cda338c>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mArithmetic\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot take an empty list\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"List must only have numbers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Cannot take an empty list"
     ]
    }
   ],
   "source": [
    "mean([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get back an error message that's more meaningful to us than \"cannot divide by zero\". We can change how we're using the function appropriately, and didn't have to dig into the implementation to understand what went wrong.\n",
    "\n",
    "Also, if we give it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "List must only have numbers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2550db19d227>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a word\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-eb8f4cda338c>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m     14\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot take an empty list\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"List must only have numbers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: List must only have numbers"
     ]
    }
   ],
   "source": [
    "mean([42, \"a word\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that our second assertion catches cases where the list has non-numbers, and complains clearly why it fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using exceptions as flexible, catchable assertions\n",
    "\n",
    "Assertions are useful for input-checking, but in production code \n",
    "it's generally better to explicitly use **exceptions**. \n",
    "An ``AssertionError`` is one type of exception, but we can use\n",
    "others to greater effect.\n",
    "\n",
    "Let's change our ``mean`` function to raise a ``ValueError`` instead\n",
    "of an ``AssertionError`` when we give an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    if len(num_list) == 0:\n",
    "        raise ValueError(\"The arithmetic mean of no elements makes no sense\")\n",
    "    return sum(num_list)/len(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The arithmetic mean of no elements makes no sense",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e9e2222d800d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-82529e4c76c8>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The arithmetic mean of no elements makes no sense\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The arithmetic mean of no elements makes no sense"
     ]
    }
   ],
   "source": [
    "mean([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raising a ``ValueError`` more [clearly defines the type of error\n",
    "indicated](https://docs.python.org/3/library/exceptions.html#ValueError): we gave a list, but it was empty. We'll see how using different types of exceptions allows us to write more flexible code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catching exceptions\n",
    "\n",
    "Let's rewrite our ``mean`` function yet again, only this time we'll put\n",
    "the meat of the function--the actual calculation--inside a ``try-except`` block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    try:\n",
    "        return sum(num_list)/len(num_list)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of raising an exception giving ``mean`` an empty list, we could\n",
    "catch the ``ZeroDivisionError`` raised by the calculation and simply\n",
    "return ``0``, which sounds sensible. It's up to us how our function\n",
    "behaves, but choosing sensible behavior is a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do something similar for the case where the list has non-number\n",
    "elements? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean(num_list):\n",
    "    try:\n",
    "        return sum(num_list)/len(num_list)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    except TypeError:\n",
    "        raise TypeError(\"Cannot get mean for non-number elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot get mean for non-number elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1d82de48a0c8>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e8c733bb99a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nothing\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-1d82de48a0c8>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(num_list)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot get mean for non-number elements\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Cannot get mean for non-number elements"
     ]
    }
   ],
   "source": [
    "mean([1, \"nothing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we caught the ``TypeError`` that results from getting the\n",
    "sum of a list with non-number elements, then we raised another\n",
    "``TypeError`` (since this is a good choice of exception for this\n",
    "issue) with a more descriptive message that tells us what is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining expected behavior with unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assertions and exceptions give mechanisms for checking that functions\n",
    "are working as expected at runtime, with the inputs given to them\n",
    "at runtime. But these don't tell us how the function will behave\n",
    "for inputs that it *might* get elsewhere at other times. How can we\n",
    "ensure that our function behaves as we expect for different assortments\n",
    "of input?\n",
    "\n",
    "We can write **unit tests**.\n",
    "\n",
    "Let's place the last version of our ``mean`` function into a module\n",
    "called ``mean.py``; open your favorite text editor and make your ``mean.py`` look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mean(num_list):\r\n",
      "    try:\r\n",
      "        return sum(num_list)/len(num_list)\r\n",
      "    except ZeroDivisionError:\r\n",
      "        return 0\r\n",
      "    except TypeError:\r\n",
      "        raise TypeError(\"Cannot get mean for non-number elements\")\r\n"
     ]
    }
   ],
   "source": [
    "%cat mean.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import this mean function directly, and use it as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mean import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a file in the same directory called ``test_mean.py`` in your\n",
    "favorite text editor, and put a single function called ``test_ints``\n",
    "inside. Don't forget to import your ``mean`` function at the top\n",
    "of this new module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mean import mean\r\n",
      "\r\n",
      "def test_ints():\r\n",
      "    num_list = [1, 2, 3, 4, 5]\r\n",
      "    obs = mean(num_list)\r\n",
      "\r\n",
      "    assert obs == 3\r\n"
     ]
    }
   ],
   "source": [
    "%cat test_mean.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've written your first unit test. This simple test\n",
    "function takes the mean of a known list of numbers, and then at the\n",
    "end asserts that the result is what we know whould be the answer. We\n",
    "can run this using ``py.test`` in the shell from the same directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.5.1, pytest-2.9.1, py-1.4.31, pluggy-0.3.1\n",
      "rootdir: /home/alter/Library/becksteinlab/ComputationalPhysics494/PHY494-resources/14_testing, inifile: \n",
      "collected 1 items\n",
      "\n",
      "test_mean.py .\n",
      "\n",
      "=========================== 1 passed in 0.01 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[py.test](http://pytest.org/) is one widely-used and \n",
    "actively-developed testing framework. It can do way more than we are\n",
    "going to use here, but it makes complex sets of tests much easier to\n",
    "build than otherwise.\n",
    "\n",
    "If we add more tests to our test suite, such that we now have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from mean import mean\r\n",
      "\r\n",
      "import pytest\r\n",
      "\r\n",
      "def test_ints():\r\n",
      "    num_list = [1, 2, 3, 4, 5]\r\n",
      "    obs = mean(num_list)\r\n",
      "\r\n",
      "    assert obs == 3\r\n",
      "\r\n",
      "def test_not_numbers():\r\n",
      "    values = [2, \"lolcats\"]\r\n",
      "    with pytest.raises(TypeError):\r\n",
      "        out = mean(values)\r\n",
      "\r\n",
      "def test_zero():\r\n",
      "    num_list = [0, 2, 4, 6]\r\n",
      "    assert mean(num_list) == 3\r\n",
      "\r\n",
      "def test_empty():\r\n",
      "    assert mean([]) == 0\r\n",
      "\r\n",
      "def test_single_int():\r\n",
      "    with pytest.raises(TypeError):\r\n",
      "        mean(1)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cat test_mean.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the special **context manager** ``pytest.raises`` used to assert that the statement that follows raises a particular exception. These are useful for making sure our function gives the expected response for\n",
    "gnarly inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ``py.test`` finds these as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.5.1, pytest-2.9.1, py-1.4.31, pluggy-0.3.1\n",
      "rootdir: /home/alter/Library/becksteinlab/ComputationalPhysics494/PHY494-resources/14_testing, inifile: \n",
      "collected 5 items\n",
      "\n",
      "test_mean.py .....\n",
      "\n",
      "=========================== 5 passed in 0.02 seconds ===========================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each test that passes, a `.` is printed. If a test failed, we'd get an `F` in that place instead, and ``py.test`` would tell us where the\n",
    "failure occurred. Let's change our function so that it returns ``None``\n",
    "instead of ``0`` for an empty list to see if this affects our tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def mean(num_list):\r\n",
      "    try:\r\n",
      "        return sum(num_list)/len(num_list)\r\n",
      "    except ZeroDivisionError:\r\n",
      "        return None\r\n",
      "    except TypeError:\r\n",
      "        raise TypeError(\"Cannot get mean for non-number elements\")\r\n"
     ]
    }
   ],
   "source": [
    "%cat mean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.5.1, pytest-2.9.1, py-1.4.31, pluggy-0.3.1\n",
      "rootdir: /home/alter/Library/becksteinlab/ComputationalPhysics494/PHY494-resources/14_testing, inifile: \n",
      "collected 5 items\n",
      "\n",
      "test_mean.py ...F.\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "__________________________________ test_empty __________________________________\n",
      "\n",
      "    def test_empty():\n",
      ">       assert mean([]) == 0\n",
      "E       assert None == 0\n",
      "E        +  where None = mean([])\n",
      "\n",
      "test_mean.py:21: AssertionError\n",
      "====================== 1 failed, 4 passed in 0.03 seconds ======================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small change was caught by one of our tests, and we see exactly\n",
    "where. This is where unit tests become immensely useful: \n",
    "if ``mean`` was part of a larger codebase and we decided to make a tiny\n",
    "change to it, we see immediately that this change affects the behavior\n",
    "expected of it by our tests. We can the decide if we **want** the new\n",
    "behavior (so we'd change the tests) or if the new behavior was a\n",
    "mistake (so we'd fix the function). \n",
    "\n",
    "Without tests, it is very hard to ensure a large amount of code\n",
    "continues behaving as we expect while we (and maybe others) keep\n",
    "working at it. The more tests we have, the more well-defined the\n",
    "expected behavior of the codebase, and the more time you will save\n",
    "scratching your head later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
